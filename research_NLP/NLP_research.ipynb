{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Text summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://towardsdatascience.com/summarizing-tweets-in-a-disaster-part-ii-67db021d378d:\n",
    "- look for situational words, describing situation or casulties using SpaCy (Numerals (eg. number of casualties, important phone numbers); Entities (eg. places, dates, events, organisations, etc.))\n",
    "    - use entity-types, look for content words\n",
    "- tf-idf score (rank somthing like \"Nepal\" highly, but not \"the\") --> use Textacy\n",
    "- clean data before tokenizing: abbreviations, misspellings (NLTK has a twitter-specific tokenizer)\n",
    "- summary of words as an ILP problem\n",
    "\n",
    "check also the notebooks\n",
    "- for SpaCy: https://github.com/gabrieltseng/datascience-projects/blob/master/natural_language_processing/twitter_disasters/spaCy/3%20-%20Abstractive%20Summary.ipynb\n",
    "- for NLTK: https://github.com/gabrieltseng/datascience-projects/blob/master/natural_language_processing/twitter_disasters/NLTK/3%20-%20Abstractive%20Summary.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ideas for overall approach: use occuring tweets as well (e.g. twitter set for wildfire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- based on https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "- also very interesting points on text pre-processing in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"KeyWordExtraction_HighLevel.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.x. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- word embeddings: https://www.wikiwand.com/en/Word_embedding --> check word2vec\n",
    "- sentiment analysis: https://www.wikiwand.com/en/Sentiment_analysis\n",
    "    - for background on singular value decomposition https://www.wikiwand.com/en/Singular_value_decomposition\n",
    "- using word graphs (powerful when there are multiple sentences describing similar situations)\n",
    "- linguistic quality: compare my sample sentence to \"normal\" English sentences\n",
    "    - see also KenLM tool at https://kheafield.com/code/kenlm/\n",
    "    - and more readings to understand this challenge http://masatohagiwara.net/training-an-n-gram-language-model-and-estimating-sentence-probability.html\n",
    "    - can be compared to current \"correct\" American English https://www.english-corpora.org/coca/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Disaster datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Twitter datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://arxiv.org/abs/1605.05894\n",
    "- https://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2834\n",
    "- https://dl.acm.org/citation.cfm?id=2914600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
